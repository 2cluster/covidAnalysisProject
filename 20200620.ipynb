{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.graph_objs as go\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "subs = pd.read_csv('./data/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Verkennende data analyse\n",
    "<br><br>\n",
    "Voor de verkennende analyse bekijken we de dataset waarmee we gaan werken. Om een goede analyse te kunnen doen is het van belang de data precies te snappen en voor de analyse een aantal aannames te doen. \n",
    "\n",
    "We beginnen met een globale analyse op de gehele dataset, van daaruit zoemen we in naar de structuur van de kolommen en zijn waardes.\n",
    "\n",
    "Wanneer dit is gedaan kunnen we een aantal simpele plots neerzetten om verbanden te zoeken en aannames te doen.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# met info kunnen we de datatype, het aantal null-waardes en de kolomnamen bekijken.\n",
    "\n",
    "train.info()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-\"*40)\n",
    "print(\"\\n\")\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# met describe bekijken we globaal de waarde in de kolommen\n",
    "\n",
    "print(train.describe())\n",
    "\n",
    "print(\"\")\n",
    "print(\"-\"*40)\n",
    "print(\"\")\n",
    "\n",
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# met head laten we de eerste 5 regels zien\n",
    "\n",
    "print(train.head())\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"-\"*40)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"weight\"] = train[\"TargetValue\"]/ train[\"Population\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(train, values='TargetValue', names='Target')\n",
    "fig.update_traces(textposition='inside')\n",
    "fig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ todo\n",
    "\n",
    "# hier moet nog een text komen over wat we zijn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ todo\n",
    "\n",
    "# hier moet nog een text komen over wat we in de plot willen laten zien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aantal bevestigde gevallen COVID19 PLOT\n",
    "x_con = train[train['Target'] == 'ConfirmedCases'].groupby('Country_Region')['TargetValue'].sum().sort_values().tail(15)\n",
    "x_con = x_con.to_frame(name = 'TargetValue').reset_index()\n",
    "fig = go.Figure(go.Bar(x=x_con[\"TargetValue\"], y=x_con[\"Country_Region\"], orientation='h'))\n",
    "fig.update_layout(title='Aantal bevestigde gevallen COVID19')\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Top 15 meeste doden door COVID19 PLOT\n",
    "x_fat = train[train['Target'] == 'Fatalities'].groupby('Country_Region')['TargetValue'].sum().sort_values().tail(15)\n",
    "x_fat = x_fat.to_frame(name = 'TargetValue').reset_index()\n",
    "fig = go.Figure(go.Bar(x=x_fat[\"TargetValue\"], y=x_fat[\"Country_Region\"], orientation='h'))\n",
    "fig.update_layout(title='Top 15 meeste doden door COVID19')\n",
    "fig.show()\n",
    "\n",
    "# deze lists gaan we later gebruiken voor een verdere analyse\n",
    "most_conf = list(x_con['Country_Region'])\n",
    "most_deaths = list(x_fat['Country_Region'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aantal bevestigde gevallen COVID19\n",
    "Dit is een barplot met op de x as de kolom ConfirmedCases en op de y as Country_Region.\n",
    "<br><br>\n",
    "\n",
    "### Top 15 meeste doden door COVID19\n",
    "Dit is een barplot met op de x as de kolom Fatalities en op de y as Country_Region. \n",
    "\n",
    "<br><br>\n",
    "### Waarneming\n",
    "De daadwerlijke cijfers liggen voor Amerika momenteel (20-05-2020) op 91.938 doden en 1.528.661 cases. Hieruit \n",
    "kunnen we concluderen dat er iets niet klopt aan de plot of dataset.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace(np.nan, '', regex=True)\n",
    "\n",
    "filter1= train[\"Country_Region\"] == 'US'\n",
    "filter2= train[\"Province_State\"] == ''\n",
    "\n",
    "temp = train.where(filter1)\n",
    "temp = temp.where(filter2)\n",
    "temp = temp.dropna()\n",
    "\n",
    "population = temp.groupby(['Province_State'])['Population'].mean().sum()\n",
    "\n",
    "print(\"De populatie van US:\")\n",
    "print(population)\n",
    "print()\n",
    "\n",
    "\n",
    "filter1= train[\"Country_Region\"] == 'US'\n",
    "\n",
    "temp = train.where(filter1)\n",
    "\n",
    "temp = temp.dropna()\n",
    "\n",
    "population = temp.groupby(['Country_Region'])['Population'].mean().sum()\n",
    "\n",
    "print(\"opgeteld alle unieke County_Region populaties:\")\n",
    "print(population)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "De absolute populatie van Amerika is ongeveer 320 miljoen. \n",
    "\n",
    "Voor de locaties in deze dataset geldt dat er in de dataset met verschillende granulatiteit word gewerkt, zowel \n",
    "1. USA\n",
    "2. USA, New York\n",
    "3. USA , New York, New York \n",
    "\n",
    "komt voor in de dataset.\n",
    "\n",
    "Dit zorgt ervoor dat als we USA selecteren we 3x dezelfde data selecteren.<br>\n",
    "\n",
    "We kunnen duseen keuze maken welke granulariteit we gaan gebruiken. Voor de verkennende analyse kiezen we ervoor om Amerika als heel land te gebruiken. Wellicht kiezen we later voor een andere granulariteit, dit zal worden bepaald door de vraag die we willen beantwoorden.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.replace(np.nan, '', regex=True)\n",
    "\n",
    "filter1= train[\"Target\"] == 'Fatalities'\n",
    "filter2= train[\"Province_State\"] == ''\n",
    "\n",
    "temp = train.where(filter1)\n",
    "temp = temp.where(filter2)\n",
    "temp = temp.dropna()\n",
    "temp.head()\n",
    "\n",
    "x_weight_f = temp.groupby(['Country_Region', 'Population'])['TargetValue'].sum().sort_values()\n",
    "x_weight_f = x_weight_f.to_frame(name='TargetValue').reset_index()\n",
    "\n",
    "x_weight_f[\"weight\"] = x_weight_f[\"TargetValue\"]/ x_weight_f[\"Population\"] * 100\n",
    "\n",
    "x_weight_f = x_weight_f.sort_values(by=\"weight\", ascending=True)\n",
    "x_weight_f1 = x_weight_f.tail(15)\n",
    "\n",
    "\n",
    "fig = go.Figure(go.Bar(x=x_weight_f1[\"weight\"], y=x_weight_f1[\"Country_Region\"], orientation='h'))\n",
    "fig.update_layout(title='Top 15 zwaarst getroffen landen op basis van populatie en aantal overledenen in percentage')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De oorspronkelijke weight die bij deze dataset hoort kunnen we niet gebruiken om de populatie van de landen te vergelijken met het aantal confirmedcases. Omdat er niet duidelijk is hoe de huidige weight berekend is gaan we hier niet mee werken, ook op het Kaggle forum valt niet duidelijk te vinden waarop deze weight gebaseerd is. Daarom hebben we zelf een weight gemaakt door de populatie van de landen te delen door de confirmed cases en fatalities. Hierboven zie je een top 15 van het percentage aantal overledenen ten opzichte van de populatie van het land. Hieronder geld dit voor de confirmed cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace(np.nan, '', regex=True)\n",
    "\n",
    "filter1= train[\"Target\"] == 'ConfirmedCases'\n",
    "filter2= train[\"Province_State\"] == ''\n",
    "\n",
    "temp = train.where(filter1)\n",
    "temp = temp.where(filter2)\n",
    "temp = temp.dropna()\n",
    "temp.head()\n",
    "\n",
    "x_weight_c = temp.groupby(['Country_Region', 'Population'])['TargetValue'].sum().sort_values()\n",
    "x_weight_c = x_weight_c.to_frame(name='TargetValue').reset_index()\n",
    "\n",
    "x_weight_c[\"weight\"] = x_weight_c[\"TargetValue\"]/ x_weight_c[\"Population\"] * 100\n",
    "\n",
    "x_weight_c = x_weight_c.sort_values(by=\"weight\", ascending=True)\n",
    "x_weight_c1 = x_weight_c.tail(15)\n",
    "\n",
    "\n",
    "fig = go.Figure(go.Bar(x=x_weight_c1[\"weight\"], y=x_weight_c1[\"Country_Region\"], orientation='h'))\n",
    "fig.update_layout(title='Top 15 zwaarst getroffen landen op basis van populatie en aantal besmettingen in percentage')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals je ziet in de bovenstaande 2 grafieken zie je dat Diamond Princess en Holy See etc. Diamond Princess is een cruiseschip waarbij een corona uitbraak heeft plaatsgevonden, Holy See is het vaticaanstad. Dit zijn allemaal plekken waarvan wij ze niet belangrijk genoeg vinden om in deze grafiek te tonen omdat de populatie van deze plekken dermate laag is dat dit het totaalpercentage besmette en overleden mensen beinvloed. Hieronder nogmaals de grafieken zonder deze plekken/landen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_weight_f = x_weight_f.where((x_weight_f[\"Country_Region\"] != \"Diamond Princess\") & (x_weight_f[\"Country_Region\"] != \"San Marino\") & (x_weight_f[\"Country_Region\"] != \"Andorra\")& (x_weight_f[\"Country_Region\"] != \"San Marino\") & (x_weight_f[\"Country_Region\"] != \"Andorra\") & (x_weight_f[\"Country_Region\"] != \"Andorra\"))\n",
    "x_weight_f2 = x_weight_f.tail(18)\n",
    "\n",
    "fig = go.Figure(go.Bar(x=x_weight_f2[\"weight\"], y=x_weight_f2[\"Country_Region\"], orientation='h'))\n",
    "fig.update_layout(title='Top 15 zwaarst getroffen landen op basis van populatie en aantal overledenen in percentage')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_weight_c = x_weight_c.where((x_weight_c[\"Country_Region\"] != \"Diamond Princess\") & (x_weight_c[\"Country_Region\"] != \"San Marino\") & (x_weight_c[\"Country_Region\"] != \"Holy See\")& (x_weight_c[\"Country_Region\"] != \"Andorra\") & (x_weight_c[\"Country_Region\"] != \"Monaco\") & (x_weight_c[\"Country_Region\"] != \"Qatar\") & (x_weight_c[\"Country_Region\"] != \"Maldives\"))\n",
    "x_weight_c2 = x_weight_c.tail(21)\n",
    "\n",
    "fig = go.Figure(go.Bar(x=x_weight_c2[\"weight\"], y=x_weight_c2[\"Country_Region\"], orientation='h'))\n",
    "fig.update_layout(title='Top 15 zwaarst getroffen landen op basis van populatie en aantal besmettingen in percentage')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om te kijken of er nog meer van dit soort landen zijn die niet relevent zijn bij onze analyse hebben we hieronder een barchart gemaakt waarin  de 30 landen staan met de laagste populatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = train.where((train[\"Province_State\"] == ''))\n",
    "pop_df = pop_df[[\"Country_Region\", \"Population\"]]\n",
    "pop_df = pop_df.drop_duplicates()\n",
    "\n",
    "pop_df = pop_df.sort_values(by=\"Population\", ascending=False)\n",
    "pop_df = pop_df.dropna()\n",
    "pop_df = pop_df.tail(30)\n",
    "\n",
    "fig = px.bar(pop_df, y='Population', x='Country_Region', text='Population')\n",
    "fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n",
    "fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide', title=\"Top 30 laagste populatie\" )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Externe factoren\n",
    "\n",
    "    - Gemiddelde leeftijd\n",
    "    - Aantal gesloten scholen\n",
    "    - Obesitas\n",
    "    - Aantal testen\n",
    "    - Arm en rijk verdeling\n",
    "    - Bevolkingsdichtheid\n",
    "    - Aantal dode per vierkante kilometer per dag\n",
    "    - Klimaat\n",
    "    - Coordinaten van landen tenopzichte van elkaar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdere toelichting per externe factor.\n",
    "- Toelichting\n",
    "- Import\n",
    "- Visualisatie\n",
    "- Analyse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date restructure\n",
    "\n",
    "Om landen in de tijd te kunnen analyseren moeten we zorgen dat de dagen de juiste schaal hebben.\n",
    "\n",
    "Dit betekend dat we geen string maar een int gaan gebruiken. we gebruiken de eerste dag en de laatste dag die voorkomt in de dataset om te bepalen wat de range word, hier loop-en we doorheen om te kijken welke dagen voorkomen in de dataset. Met deze dagen bouwen we een dict op om de nieuwe index toe te passen \n",
    "\n",
    "> nergens word gehardcode zodat wanneer de dataset meer datums bevat de code blijft werken\n",
    "\n",
    "> we gaan ervanuit dat er geen datums tussen de eerste dag en de laatste dag bestaan die in de dataset missen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train\n",
    "test_df = test\n",
    "\n",
    "\n",
    "# - verwijderen om als int te kunnen casten\n",
    "train_df[\"Date\"] = train_df[\"Date\"].replace({'-': ''}, regex=True)\n",
    "test_df[\"Date\"] = test_df[\"Date\"].replace({'-': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kolom casten naar int\n",
    "\n",
    "train_df[\"Date\"] = pd.to_numeric(train_df[\"Date\"])\n",
    "test_df[\"Date\"] = pd.to_numeric(test_df[\"Date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wat is de range van datums\n",
    "\n",
    "min_date = train_df['Date'].min()\n",
    "max_date = test_df['Date'].max()\n",
    "print(min_date)\n",
    "print(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_values = \"\"\n",
    "custom_index = 0\n",
    "\n",
    "for i in range(int(min_date), (int(max_date)+1)):\n",
    "    \n",
    "    # komt het getal in de dataset voor?\n",
    "    if i in train_df['Date'].unique():\n",
    "        \n",
    "        # ja, voeg een entry toe aan de dict <   20200101: 1,   >\n",
    "        dict_values += str(i) + \": \" + str(custom_index) + \", \"\n",
    "        custom_index+=1\n",
    "        \n",
    "    elif i in test_df['Date'].unique():\n",
    "        dict_values += str(i) + \": \" + str(custom_index) + \", \"\n",
    "        custom_index+=1\n",
    "        \n",
    "exec(\"date_dict = {\" + dict_values + \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(date_dict[20200501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Date'] = train_df['Date'].replace(date_dict)\n",
    "test_df['Date'] = test_df['Date'].replace(date_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_locations = train_df.Country_Region.unique()\n",
    "unique_targets = train_df.Target.unique()\n",
    "\n",
    "print(\"There are \"+str(len(unique_locations))+\"\\t unique locations\")\n",
    "print(\"There are \"+str(len(unique_targets))+\"\\t unique Targets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import random\n",
    "r = lambda: random.randint(0,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = \\\n",
    "    [\n",
    "    \"Netherlands\",\n",
    "    \"Belgium\",\n",
    "    \"Spain\",\n",
    "    \"Germany\",\n",
    "    \"Sweden\",\n",
    "    \"United Kingdom\",\n",
    "    \"Italy\",\n",
    "    \"France\"\n",
    "    ]\n",
    "\n",
    "for tar in unique_targets:\n",
    "    for loc in countries: \n",
    "        filter1 = train_df[\"Target\"]==tar\n",
    "        filter2 = train_df[\"Province_State\"]==''\n",
    "        filter3 = train_df[\"Country_Region\"]==loc\n",
    "        filter4 = train_df[\"TargetValue\"]!=0\n",
    "        \n",
    "        temp = train_df.where(filter1)\n",
    "        temp = temp.where(filter2)\n",
    "        temp = temp.where(filter3)\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        \n",
    "        temp2 = temp.where(filter4)\n",
    "        print('day {} is the first day of a {} value in {}.'.format(int(temp2[\"Date\"].min()), tar, loc))\n",
    "        \n",
    "        \n",
    "\n",
    "        x = temp[\"Date\"]\n",
    "        y = temp[\"weight\"]\n",
    "        \n",
    "        ysmoothed = gaussian_filter1d(y, sigma=6)\n",
    "\n",
    "        temp['ysmooth'] = ysmoothed\n",
    "  \n",
    "\n",
    "        fig = px.line(temp, x=x, y=y, color='Country_Region', color_discrete_sequence=['rgb({},{},{})'.format(r(),r(),r())])\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "countries = \\\n",
    "    [\n",
    "            \"Belgium\",\n",
    "            \"Spain\",\n",
    "            \"United Kingdom\",\n",
    "            \"Italy\",\n",
    "            \"France\"\n",
    "            ]\n",
    "\n",
    "for tar in unique_targets:\n",
    "    \n",
    "    \n",
    "    for loc in countries: \n",
    "        filter1 = train_df[\"Target\"]==tar\n",
    "        filter2 = train_df[\"Province_State\"]==''\n",
    "        filter3 = train_df[\"Country_Region\"]==loc\n",
    "        filter4 = train_df[\"TargetValue\"]!=0\n",
    "        \n",
    "        temp = train_df.where(filter1)\n",
    "        temp = temp.where(filter2)\n",
    "        temp = temp.where(filter3)\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        \n",
    "        temp2 = temp.where(filter4)\n",
    "#         print('day {} is the first day of a {} value in {}.'.format(int(temp2[\"Date\"].min()), tar, loc))\n",
    "        \n",
    "        \n",
    "\n",
    "        x = temp[\"Date\"]\n",
    "        y = temp[\"weight\"]\n",
    "               \n",
    "        \n",
    "        ysmoothed = gaussian_filter1d(y, sigma=6)\n",
    "        date_min = int(temp2[\"Date\"].min())  \n",
    " \n",
    "        real_peak_value = y.max()\n",
    "        real_peak_index  = np.where(y == np.amax(y))[0][0]\n",
    "        \n",
    "        gaus_peak_value = ysmoothed.max()\n",
    "        gaus_peak_index  = np.where(ysmoothed == np.amax(ysmoothed))[0][0]\n",
    "\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(go.Scatter(x=x, y=ysmoothed,\n",
    "                    mode='lines',\n",
    "                    name='lines', line=dict(color=\"black\")))\n",
    "\n",
    "        \n",
    "        fig.add_trace(go.Scatter(x=[gaus_peak_index], y=[gaus_peak_value],\n",
    "                    mode='markers', name='markers', marker=dict(size=12, symbol=\"x\", opacity=1, color='black')))\n",
    "        \n",
    "        fig.add_trace(go.Scatter(x=x[date_min:], y=y[date_min:],\n",
    "                    mode='markers', name='markers', marker=dict(size=4, opacity=0.5, color='red')))\n",
    "        \n",
    "      \n",
    "        fig.add_trace(go.Scatter(x=[real_peak_index, date_min], y=[ysmoothed[real_peak_index],ysmoothed[date_min]],\n",
    "                    mode='markers', name='markers', marker=dict(size=12, symbol=\"x\", opacity=1, color='red')))\n",
    "        \n",
    "        \n",
    "\n",
    "        fig.show()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "countries = \\\n",
    "    [\n",
    "    \"Belgium\",\n",
    "    \"Spain\",\n",
    "    \"United Kingdom\",\n",
    "    \"Italy\",\n",
    "    \"France\"\n",
    "    ]\n",
    "\n",
    "\n",
    "for tar in unique_targets:\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for loc in countries: \n",
    "        filter1 = train_df[\"Target\"]==tar\n",
    "        filter2 = train_df[\"Province_State\"]==''\n",
    "        filter3 = train_df[\"Country_Region\"]==loc\n",
    "        filter4 = train_df[\"TargetValue\"]!=0\n",
    "        \n",
    "        temp = train_df.where(filter1)\n",
    "        temp = temp.where(filter2)\n",
    "        temp = temp.where(filter3)\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        \n",
    "        temp2 = temp.where(filter4)\n",
    "        print('day {} is the first day of a {} value in {}.'.format(int(temp2[\"Date\"].min()), tar, loc))\n",
    "        date_min = int(temp2[\"Date\"].min())  \n",
    "        \n",
    "        df = temp  \n",
    "        \n",
    "        ysmoothed = gaussian_filter1d(df['weight'], sigma=6)\n",
    "        df['ysmooth'] = ysmoothed\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        fig.add_trace(go.Scatter(x=x, y=ysmoothed,\n",
    "                    mode='lines',\n",
    "                    name=loc, \n",
    "                    line=dict(\n",
    "                        color='rgb({},{},{})'.format(r(),r(),r()))))\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = \\\n",
    "    [\n",
    "    \"Belgium\",\n",
    "    \"Spain\",\n",
    "    \"United Kingdom\",\n",
    "    \"Italy\",\n",
    "    \"France\"\n",
    "    ]\n",
    "\n",
    "\n",
    "for tar in unique_targets:\n",
    "    apended_df = pd.DataFrame(columns=['Id', 'County', 'Province_State', 'Country_Region', 'Population',\n",
    "       'Weight', 'Date', 'Target', 'TargetValue', 'ysmooth', 'cycle_index'])\n",
    "    for loc in countries: \n",
    "        filter1 = train_df[\"Target\"]==tar\n",
    "        filter2 = train_df[\"Province_State\"]==''\n",
    "        filter3 = train_df[\"Country_Region\"]==loc\n",
    "        filter4 = train_df[\"TargetValue\"]!=0\n",
    "        \n",
    "        temp = train_df.where(filter1)\n",
    "        temp = temp.where(filter2)\n",
    "        temp = temp.where(filter3)\n",
    "        temp = temp.dropna()\n",
    "        \n",
    "        \n",
    "        temp2 = temp.where(filter4)\n",
    "        print('day {} is the first day of a {} value in {}.'.format(int(temp2[\"Date\"].min()), tar, loc))\n",
    "        date_min = int(temp2[\"Date\"].min())  \n",
    "        \n",
    "\n",
    "        df = temp[date_min:]\n",
    "        ysmoothed = gaussian_filter1d(df['weight'], sigma=6)\n",
    "        df['ysmooth'] = ysmoothed\n",
    "        df['cycle_index'] = [l for l in range(1, len(df)+1)]\n",
    "        apended_df = pd.concat([apended_df,df])\n",
    "    apended_df['cycle_index'].replace(np.nan, 0)    \n",
    "    fig = px.line(apended_df, x='cycle_index', y='ysmooth', color='Country_Region')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
